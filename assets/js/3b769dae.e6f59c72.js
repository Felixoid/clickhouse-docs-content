"use strict";(self.webpackChunkclickhouse=self.webpackChunkclickhouse||[]).push([[8403],{3905:function(e,t,n){n.d(t,{Zo:function(){return m},kt:function(){return p}});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=a.createContext({}),l=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=l(e.components);return a.createElement(d.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,d=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),u=l(n),p=r,b=u["".concat(d,".").concat(p)]||u[p]||c[p]||i;return n?a.createElement(b,o(o({ref:t},m),{},{components:n})):a.createElement(b,o({ref:t},m))}));function p(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var d in t)hasOwnProperty.call(t,d)&&(s[d]=t[d]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var l=2;l<i;l++)o[l]=n[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},77554:function(e,t,n){n.r(t),n.d(t,{assets:function(){return m},contentTitle:function(){return d},default:function(){return p},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return c}});var a=n(87462),r=n(63366),i=(n(67294),n(3905)),o=["components"],s={sidebar_label:"Incremental Materializations",sidebar_position:6,description:"Table materializations with dbt and ClickHouse"},d="Creating an Incremental Materialization",l={unversionedId:"en/integrations/dbt/dbt-incremental-model",id:"en/integrations/dbt/dbt-incremental-model",title:"Creating an Incremental Materialization",description:"Table materializations with dbt and ClickHouse",source:"@site/docs/en/integrations/dbt/dbt-incremental-model.md",sourceDirName:"en/integrations/dbt",slug:"/en/integrations/dbt/dbt-incremental-model",permalink:"/docs/en/integrations/dbt/dbt-incremental-model",editUrl:"https://github.com/ClickHouse/clickhouse-docs/blob/main/docs/en/integrations/dbt/dbt-incremental-model.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{sidebar_label:"Incremental Materializations",sidebar_position:6,description:"Table materializations with dbt and ClickHouse"},sidebar:"english",previous:{title:"Table Materializations",permalink:"/docs/en/integrations/dbt/dbt-table-model"},next:{title:"Seeds",permalink:"/docs/en/integrations/dbt/dbt-seeds"}},m={},c=[{value:"Internals",id:"internals",level:2}],u={toc:c};function p(e){var t=e.components,n=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"creating-an-incremental-materialization"},"Creating an Incremental Materialization"),(0,i.kt)("p",null,"In the previous example, we created a table to materialize the model. This table will be reconstructed for each dbt execution. This may be infeasible and extremely costly for larger result sets or complex transformations. To address this challenge and reduce the build time, dbt offers Incremental materializations. This allows dbt to insert or update records into a table since the last execution, making it appropriate for event-style data. While this is supported by the ClickHouse plugin, it does come with some ",(0,i.kt)("a",{parentName:"p",href:"./dbt-limitations"},"Limitations")," users should be aware of."),(0,i.kt)("p",null,'To illustrate this example, we will add the actor "Clicky McClickHouse", who will appear in an incredible 910 movies - ensuring he has appeared in more films than even ',(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Mel_Blanc"},"Mel Blanc"),"."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"First, we modify our model to be of type incremental. This addition requires:"),(0,i.kt)("ol",{parentName:"li"},(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"unique_key")," - To ensure the plugin can uniquely identify rows, we must provide a unique_key - in this case, the ",(0,i.kt)("inlineCode",{parentName:"li"},"id")," field from our query will suffice. This ensures we will have no row duplicates in our materialized table. For more details on uniqueness constraints, see",(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models#defining-a-uniqueness-constraint-optional"}," here"),"."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Incremental filter")," - We also need to tell dbt how it should identify which rows have changed on an incremental run. This is achieved by providing a delta expression. Typically this involves a timestamp for event data; hence our updated_at timestamp field. This column, which defaults to the value of now() when rows are inserted, allows new roles to be identified. Additionally, we need to identify the alternative case where new actors are added. Using the {{this}} variable, to denote the existing materialized table, this gives us the expression ",(0,i.kt)("inlineCode",{parentName:"li"},"where id > (select max(id) from {{ this }}) and updated_at > (select max(created_at) from {{this}})"),". We embed this inside the ",(0,i.kt)("inlineCode",{parentName:"li"},"{% if is_incremental() %}")," condition, ensuring it is only used on incremental runs and not when the table is first constructed. For more details on filtering rows for incremental models, see ",(0,i.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models#filtering-rows-on-an-incremental-run"},"this discussion in the dbt docs"),".")),(0,i.kt)("p",{parentName:"li"},"Update the file ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary.sql")," with the following:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"{{ config(order_by='(updated_at, id, name)', engine='MergeTree()', materialized='incremental',\nunique_key='id') }}\n")),(0,i.kt)("p",{parentName:"li"},"Note that our model will only respond to updates and additions to the ",(0,i.kt)("inlineCode",{parentName:"p"},"roles")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"actors")," tables. To respond to all tables, users would be encouraged to split this model into multiple sub models - each with their own incremental criteria. These models can in turn be referenced and connected. For further details on cross referencing models see ",(0,i.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/reference/dbt-jinja-functions/ref"},"here"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute a ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run")," and confirm the results of the resulting table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$  dbt run\n15:33:34  Running with dbt=1.0.4\n15:33:34  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n15:33:34\n15:33:35  Concurrency: 1 threads (target='dev')\n15:33:35\n15:33:35  1 of 1 START incremental model imdb_dbt.actor_summary........................... [RUN]\n15:33:41  1 of 1 OK created incremental model imdb_dbt.actor_summary...................... [OK in 6.33s]\n15:33:41\n15:33:41  Finished running 1 incremental model in 7.30s.\n15:33:41\n15:33:41  Completed successfully\n15:33:41\n15:33:41  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 5;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+------------+----------+------------------+------+---------+-------------------+\n|id    |name        |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+------------+----------+------------------+------+---------+-------------------+\n|45332 |Mel Blanc   |832       |6.175853582979779 |18    |84       |2022-04-26 15:26:55|\n|621468|Bess Flowers|659       |5.57727638854796  |19    |293      |2022-04-26 15:26:57|\n|372839|Lee Phelps  |527       |5.032976449684617 |18    |261      |2022-04-26 15:26:56|\n|283127|Tom London  |525       |2.8721716524875673|17    |203      |2022-04-26 15:26:56|\n|356804|Bud Osborne |515       |2.0389507108727773|15    |149      |2022-04-26 15:26:56|\n+------+------------+----------+------------------+------+---------+-------------------+\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},'We will now add data to our model to illustrate an incremental update. Add our actor  "Clicky McClickHouse" to the ',(0,i.kt)("inlineCode",{parentName:"p"},"actors")," table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.actors VALUES (845466, 'Clicky', 'McClickHouse', 'M');\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Let's star Clicky in 910 random movies:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO imdb.roles\nSELECT now() as created_at, 845466 as actor_id, id as movie_id, 'Himself' as role\nFROM imdb.movies\nLIMIT 910 OFFSET 10000;\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Confirm he is indeed now the actor with the most appearances by querying the underlying source table and bypassing any dbt models:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT id,\n    any(actor_name)          as name,\n    uniqExact(movie_id)    as num_movies,\n    avg(rank)                as avg_rank,\n    uniqExact(genre)         as unique_genres,\n    uniqExact(director_name) as uniq_directors,\n    max(created_at)          as updated_at\nFROM (\n        SELECT imdb.actors.id                                                   as id,\n                concat(imdb.actors.first_name, ' ', imdb.actors.last_name)       as actor_name,\n                imdb.movies.id as movie_id,\n                imdb.movies.rank                                                 as rank,\n                genre,\n                concat(imdb.directors.first_name, ' ', imdb.directors.last_name) as director_name,\n                created_at\n        FROM imdb.actors\n                JOIN imdb.roles ON imdb.roles.actor_id = imdb.actors.id\n                LEFT OUTER JOIN imdb.movies ON imdb.movies.id = imdb.roles.movie_id\n                LEFT OUTER JOIN imdb.genres ON imdb.genres.movie_id = imdb.movies.id\n                LEFT OUTER JOIN imdb.movie_directors ON imdb.movie_directors.movie_id = imdb.movies.id\n                LEFT OUTER JOIN imdb.directors ON imdb.directors.id = imdb.movie_directors.director_id\n        )\nGROUP BY id\nORDER BY num_movies DESC\nLIMIT 2;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+-------------------+----------+------------------+------+---------+-------------------+\n|id    |name               |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+-------------------+----------+------------------+------+---------+-------------------+\n|845466|Clicky McClickHouse|910       |1.4687938697032283|21    |662      |2022-04-26 16:20:36|\n|45332 |Mel Blanc          |909       |5.7884792542982515|19    |148      |2022-04-26 16:17:42|\n+------+-------------------+----------+------------------+------+---------+-------------------+\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Execute a ",(0,i.kt)("inlineCode",{parentName:"p"},"dbt run")," and confirm our model has been updated and matches the above results:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"clickhouse-user@clickhouse:~/imdb$  dbt run\n16:12:16  Running with dbt=1.0.4\n16:12:16  Found 1 model, 0 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 6 sources, 0 exposures, 0 metrics\n16:12:16\n16:12:17  Concurrency: 1 threads (target='dev')\n16:12:17\n16:12:17  1 of 1 START incremental model imdb_dbt.actor_summary........................... [RUN]\n16:12:24  1 of 1 OK created incremental model imdb_dbt.actor_summary...................... [OK in 6.82s]\n16:12:24\n16:12:24  Finished running 1 incremental model in 7.79s.\n16:12:24\n16:12:24  Completed successfully\n16:12:24\n16:12:24  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM imdb_dbt.actor_summary ORDER BY num_movies DESC LIMIT 2;\n")),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-response"},"+------+-------------------+----------+------------------+------+---------+-------------------+\n|id    |name               |num_movies|avg_rank          |genres|directors|updated_at         |\n+------+-------------------+----------+------------------+------+---------+-------------------+\n|845466|Clicky McClickHouse|910       |1.4687938697032283|21    |662      |2022-04-26 16:20:36|\n|45332 |Mel Blanc          |909       |5.7884792542982515|19    |148      |2022-04-26 16:17:42|\n+------+-------------------+----------+------------------+------+---------+-------------------+\n")))),(0,i.kt)("h2",{id:"internals"},"Internals"),(0,i.kt)("p",null,"We can identify the statements executed to achieve the above incremental update by querying ClickHouse\u2019s query log."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT event_time, query  FROM system.query_log WHERE type='QueryStart' AND query LIKE '%dbt%'\nAND event_time > subtractMinutes(now(), 15) ORDER BY event_time LIMIT 100;\n")),(0,i.kt)("p",null,"Adjust the above query to the period of execution. We leave result inspection to the user but highlight the general strategy used by the plugin to perform incremental updates:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The plugin creates a temporary table ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_sumary__dbt_tmp")," using the ",(0,i.kt)("a",{parentName:"p",href:"https://clickhouse.com/docs/en/engines/table-engines/special/memory"},"Memory engine"),". Rows that have changed are streamed into this table."),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"create temporary table actor_summary__dbt_tmp\n    engine = Memory\n        order by ((updated_at, id, name))\nas (with actor_summary as (SELECT id,\n            any(actor_name)          as name,\n            uniqExact(movie_id)      as num_movies,\n            avg(rank)                as avg_rank,\n            uniqExact(genre)         as genres,\n            uniqExact(director_name) as directors,\n            max(created_at)          as updated_at\n            FROM (\n                SELECT imdb.actors.id                                                   as id,\n                    concat(imdb.actors.first_name, ' ', imdb.actors.last_name)       as actor_name,\n                    imdb.movies.id                                                   as movie_id,\n                    imdb.movies.rank                                                 as rank,\n                    genre,\n                    concat(imdb.directors.first_name, ' ', imdb.directors.last_name) as director_name,\n                    created_at\n                FROM imdb.actors\n                        JOIN imdb.roles ON imdb.roles.actor_id = imdb.actors.id\n                        LEFT OUTER JOIN imdb.movies ON imdb.movies.id = imdb.roles.movie_id\n                        LEFT OUTER JOIN imdb.genres ON imdb.genres.movie_id = imdb.movies.id\n                        LEFT OUTER JOIN imdb.movie_directors ON imdb.movie_directors.movie_id = imdb.movies.id\n                        LEFT OUTER JOIN imdb.directors ON imdb.directors.id = imdb.movie_directors.director_id\n                )\n    GROUP BY id)\n\n    select *\n    from actor_summary\n\n    where id > (select max(id) from imdb_dbt.actor_summary)\n    or updated_at > (select max(updated_at) from imdb_dbt.actor_summary));\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"The previous materialized table is renamed ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary_old"),". A new table ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary")," is created. The rows from the old table are, in turn, streamed from the old to new, with a check to make sure row ids do not exist in the temporary table. This effectively handles updates:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},'insert into imdb_dbt.actor_summary ("id", "name", "num_movies", "avg_rank", "genres", "directors", "updated_at")\nselect "id", "name", "num_movies", "avg_rank", "genres", "directors", "updated_at"\nfrom imdb_dbt.actor_summary__dbt_old\nwhere (id) not in (select (id)\n                from actor_summary__dbt_tmp);\n'))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Finally, results from the temporary table are streamed into the new ",(0,i.kt)("inlineCode",{parentName:"p"},"actor_summary")," table:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},'insert into imdb_dbt.actor_summary ("id", "name", "num_movies", "avg_rank", "genres", "directors", "updated_at")\nselect "id", "name", "num_movies", "avg_rank", "genres", "directors", "updated_at"\nfrom actor_summary__dbt_tmp;\n')))),(0,i.kt)("p",null,"This strategy may encounter challenges on very large models. For further details see ",(0,i.kt)("a",{parentName:"p",href:"./dbt-limitations"},"Limitations"),"."))}p.isMDXComponent=!0}}]);